{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef09862",
   "metadata": {},
   "source": [
    "!pip install lightning pytorch-forecasting --quiet\n",
    "\n",
    "# ==============================\n",
    "# 1) Imports and seed\n",
    "# ==============================\n",
    "import os, glob, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# ==============================\n",
    "# 2) Locate data and model files\n",
    "# ==============================\n",
    "base_dir = \"/kaggle/input/iess-demand-2002-2025\"\n",
    "csv_candidates = []\n",
    "for ext in (\"*.csv\", \"*.CSV\"):\n",
    "    csv_candidates.extend(glob.glob(os.path.join(base_dir, \"**\", ext), recursive=True))\n",
    "assert len(csv_candidates) > 0, \"No CSV files found under /kaggle/input/iess-demand-2002-2025\"\n",
    "csv_path = max(csv_candidates, key=os.path.getsize)\n",
    "print(f\"Using historical file: {csv_path}\")\n",
    "\n",
    "model_input_slug = \"results2\"\n",
    "model_dir = f\"/kaggle/input/{model_input_slug}\"\n",
    "best_checkpoint = os.path.join(model_dir, \"tft_best_model.ckpt\")\n",
    "\n",
    "assert os.path.exists(best_checkpoint), f\"Checkpoint not found at {best_checkpoint}\"\n",
    "print(f\"Using checkpoint: {best_checkpoint}\")\n",
    "\n",
    "# ==============================\n",
    "# 3) Load & preprocess historical data\n",
    "# ==============================\n",
    "df = pd.read_csv(csv_path)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "assert \"Ontario Demand\" in df.columns, \"Expected 'Ontario Demand' column\"\n",
    "df = df.drop(columns=[\"Market Demand\"], errors=\"ignore\")\n",
    "\n",
    "df[\"Hour\"] = pd.to_numeric(df[\"Hour\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Date\", \"Hour\"]).copy()\n",
    "df[\"Hour\"] = df[\"Hour\"].astype(int).clip(1, 24)\n",
    "\n",
    "df[\"time\"] = df[\"Date\"] + pd.to_timedelta(df[\"Hour\"] - 1, unit=\"h\")\n",
    "df[\"Ontario Demand\"] = pd.to_numeric(df[\"Ontario Demand\"], errors=\"coerce\")\n",
    "\n",
    "df = df.dropna(subset=[\"Ontario Demand\", \"time\"]).sort_values(\"time\").reset_index(drop=True)\n",
    "df = df.drop_duplicates(subset=[\"time\"], keep=\"first\").sort_values(\"time\")\n",
    "\n",
    "full_range = pd.date_range(df[\"time\"].min(), df[\"time\"].max(), freq=\"h\")\n",
    "df = df.set_index(\"time\").reindex(full_range).rename_axis(\"time\").reset_index()\n",
    "\n",
    "# Forward-fill only (match training preprocessing)\n",
    "df[\"Ontario Demand\"] = df[\"Ontario Demand\"].astype(float).ffill()\n",
    "\n",
    "df[\"series\"] = \"ON\"\n",
    "df[\"time_idx\"] = ((df[\"time\"] - df[\"time\"].min()).dt.total_seconds() // 3600).astype(int)\n",
    "df[\"hour\"] = df[\"time\"].dt.hour.astype(\"int16\")\n",
    "df[\"day_of_week\"] = df[\"time\"].dt.dayofweek.astype(\"int8\")\n",
    "df[\"month\"] = df[\"time\"].dt.month.astype(\"int8\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "print(\"\\nHistorical data loaded and preprocessed.\")\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Last timestamp in database: {df['time'].max()}\")\n",
    "print(f\"Last known demand: {df['Ontario Demand'].iloc[-1]:.1f} MW\")\n",
    "print(f\"Ontario Demand range: {df['Ontario Demand'].min():.1f} to {df['Ontario Demand'].max():.1f} MW\")\n",
    "\n",
    "# ==============================\n",
    "# 4) Checkpoint diagnostics\n",
    "# ==============================\n",
    "print(\"\\n=== CHECKPOINT DIAGNOSTICS ===\")\n",
    "checkpoint = torch.load(best_checkpoint, map_location='cpu', weights_only=False)\n",
    "\n",
    "if 'hyper_parameters' in checkpoint:\n",
    "    hparams = checkpoint['hyper_parameters']\n",
    "    print(f\"Model was trained with:\")\n",
    "    print(f\"  - max_encoder_length: {hparams.get('max_encoder_length', 'N/A')}\")\n",
    "    print(f\"  - max_prediction_length: {hparams.get('max_prediction_length', 'N/A')}\")\n",
    "    \n",
    "    if 'target_normalizer' in hparams:\n",
    "        normalizer = hparams['target_normalizer']\n",
    "        print(f\"  - target_normalizer: {type(normalizer).__name__}\")\n",
    "        if hasattr(normalizer, 'transformation'):\n",
    "            print(f\"    transformation: {normalizer.transformation}\")\n",
    "        if hasattr(normalizer, 'center'):\n",
    "            print(f\"    center: {normalizer.center}\")\n",
    "\n",
    "# ==============================\n",
    "# 5) Create reference training dataset - MATCH TRAINING EXACTLY\n",
    "# ==============================\n",
    "max_encoder_length = 168\n",
    "max_prediction_length = 24\n",
    "\n",
    "# CRITICAL: Use EXACT same normalizer as training (no softplus, no center=False)\n",
    "training = TimeSeriesDataSet(\n",
    "    df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Ontario Demand\",\n",
    "    group_ids=[\"series\"],\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    \n",
    "    time_varying_known_reals=[\"time_idx\", \"hour\", \"day_of_week\", \"month\"],\n",
    "    time_varying_unknown_reals=[\"Ontario Demand\"],\n",
    "    \n",
    "    # CRITICAL: Match training configuration exactly\n",
    "    target_normalizer=GroupNormalizer(groups=[\"series\"]),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    allow_missing_timesteps=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nReference training dataset created with {len(training)} samples\")\n",
    "\n",
    "# ==============================\n",
    "# 6) Prepare data for NEXT DAY prediction\n",
    "# ==============================\n",
    "last_time = df[\"time\"].max()\n",
    "last_time_idx = df[\"time_idx\"].max()\n",
    "last_demand = df[\"Ontario Demand\"].iloc[-1]\n",
    "\n",
    "# Create future timestamps\n",
    "future_times = pd.date_range(\n",
    "    start=last_time + pd.Timedelta(hours=1),\n",
    "    periods=max_prediction_length, \n",
    "    freq=\"h\"\n",
    ")\n",
    "\n",
    "print(f\"\\n=== PREDICTION SETUP ===\")\n",
    "print(f\"Last database entry: {last_time} ({last_demand:.1f} MW)\")\n",
    "print(f\"Prediction period: {future_times[0]} to {future_times[-1]}\")\n",
    "print(f\"Prediction day: {future_times[0].strftime('%A, %B %d, %Y')}\")\n",
    "\n",
    "# Create prediction dataframe with FUTURE data\n",
    "# Use last known demand as placeholder (better than 0)\n",
    "future_rows = pd.DataFrame({\n",
    "    \"time\": future_times,\n",
    "    \"series\": \"ON\",\n",
    "    \"Ontario Demand\": last_demand,  # Use realistic placeholder instead of 0\n",
    "    \"hour\": future_times.hour.astype(\"int16\"),\n",
    "    \"day_of_week\": future_times.dayofweek.astype(\"int8\"),\n",
    "    \"month\": future_times.month.astype(\"int8\"),\n",
    "})\n",
    "\n",
    "# Recalculate time_idx for future rows\n",
    "future_rows[\"time_idx\"] = ((future_rows[\"time\"] - df[\"time\"].min()).dt.total_seconds() // 3600).astype(int)\n",
    "\n",
    "# Combine historical + future\n",
    "prediction_df = pd.concat([df, future_rows], ignore_index=True)\n",
    "\n",
    "# Verify encoder data\n",
    "encoder_data = prediction_df[prediction_df[\"time_idx\"] <= last_time_idx].tail(max_encoder_length)\n",
    "print(f\"\\nEncoder data verification:\")\n",
    "print(f\"  Length: {len(encoder_data)} hours\")\n",
    "print(f\"  Time range: {encoder_data['time'].min()} to {encoder_data['time'].max()}\")\n",
    "print(f\"  Demand range: {encoder_data['Ontario Demand'].min():.1f} to {encoder_data['Ontario Demand'].max():.1f} MW\")\n",
    "print(f\"  Last encoder demand: {encoder_data['Ontario Demand'].iloc[-1]:.1f} MW\")\n",
    "\n",
    "# ==============================\n",
    "# 7) Create prediction dataset using from_dataset\n",
    "# ==============================\n",
    "prediction_dataset = TimeSeriesDataSet.from_dataset(\n",
    "    training,\n",
    "    prediction_df,\n",
    "    predict=True,\n",
    "    stop_randomization=True\n",
    ")\n",
    "\n",
    "predict_loader = prediction_dataset.to_dataloader(\n",
    "    train=False, \n",
    "    batch_size=1,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"\\nPrediction dataset created with {len(prediction_dataset)} samples\")\n",
    "\n",
    "# ==============================\n",
    "# 8) Load model from checkpoint\n",
    "# ==============================\n",
    "print(\"\\n=== LOADING MODEL ===\")\n",
    "\n",
    "try:\n",
    "    tft = TemporalFusionTransformer.load_from_checkpoint(best_checkpoint)\n",
    "    print(\"✓ Model loaded using load_from_checkpoint()\")\n",
    "except Exception as e:\n",
    "    print(f\"Primary loading failed: {e}\")\n",
    "    print(\"Attempting alternative method...\")\n",
    "    \n",
    "    tft = TemporalFusionTransformer.from_dataset(\n",
    "        training,\n",
    "        learning_rate=1e-3,\n",
    "        hidden_size=32,\n",
    "        attention_head_size=4,\n",
    "        dropout=0.1,\n",
    "        hidden_continuous_size=16,\n",
    "        loss=QuantileLoss(),\n",
    "        optimizer=\"Adam\",\n",
    "    )\n",
    "    \n",
    "    checkpoint = torch.load(best_checkpoint, map_location='cpu', weights_only=False)\n",
    "    tft.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "    print(\"✓ Model loaded using manual state_dict\")\n",
    "\n",
    "tft.eval()\n",
    "print(\"✓ Model set to evaluation mode\")\n",
    "\n",
    "# Verify model normalizer matches (access from dataset instead)\n",
    "try:\n",
    "    if hasattr(tft, 'dataset_parameters'):\n",
    "        normalizer = tft.dataset_parameters.get('target_normalizer')\n",
    "    elif hasattr(training, 'target_normalizer'):\n",
    "        normalizer = training.target_normalizer\n",
    "    else:\n",
    "        normalizer = None\n",
    "    \n",
    "    if normalizer:\n",
    "        print(f\"\\nDataset normalizer type: {type(normalizer).__name__}\")\n",
    "        if hasattr(normalizer, 'transformation'):\n",
    "            print(f\"  transformation: {normalizer.transformation}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nNote: Could not inspect normalizer details: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# 9) Generate predictions\n",
    "# ==============================\n",
    "print(\"\\n=== GENERATING PREDICTIONS ===\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    raw_predictions = tft.predict(\n",
    "        predict_loader, \n",
    "        mode=\"prediction\",\n",
    "        return_x=False,\n",
    "        return_index=False\n",
    "    )\n",
    "\n",
    "# Extract predictions\n",
    "if isinstance(raw_predictions, torch.Tensor):\n",
    "    predictions = raw_predictions.detach().cpu().numpy()\n",
    "else:\n",
    "    predictions = raw_predictions\n",
    "\n",
    "# Handle different output shapes\n",
    "if predictions.ndim == 3:\n",
    "    predictions = predictions[0, :, 0]\n",
    "elif predictions.ndim == 2:\n",
    "    predictions = predictions[0, :]\n",
    "else:\n",
    "    predictions = predictions.flatten()\n",
    "\n",
    "# Ensure we have exactly 24 predictions\n",
    "predictions = predictions[:max_prediction_length]\n",
    "\n",
    "print(f\"✓ Predictions generated\")\n",
    "print(f\"  Shape: {predictions.shape}\")\n",
    "print(f\"  Range: {predictions.min():.1f} to {predictions.max():.1f} MW\")\n",
    "print(f\"  Mean: {predictions.mean():.1f} MW\")\n",
    "\n",
    "# Sanity check: Compare to historical scale\n",
    "historical_mean = df[\"Ontario Demand\"].tail(168).mean()\n",
    "print(f\"\\nScale validation:\")\n",
    "print(f\"  Historical mean (last 7 days): {historical_mean:.1f} MW\")\n",
    "print(f\"  Prediction mean: {predictions.mean():.1f} MW\")\n",
    "print(f\"  Difference: {abs(predictions.mean() - historical_mean):.1f} MW\")\n",
    "\n",
    "if abs(predictions.mean() - historical_mean) > 5000:\n",
    "    print(\"  ⚠️ WARNING: Predictions significantly different from historical scale!\")\n",
    "else:\n",
    "    print(\"  ✓ Predictions within expected scale\")\n",
    "\n",
    "# ==============================\n",
    "# 10) Create output dataframe\n",
    "# ==============================\n",
    "output_df = pd.DataFrame({\n",
    "    \"time\": future_times[:len(predictions)],\n",
    "    \"predicted_ontario_demand\": predictions,\n",
    "    \"horizon_hour_ahead\": np.arange(1, len(predictions) + 1),\n",
    "    \"hour_of_day\": future_times[:len(predictions)].hour,\n",
    "    \"day_of_week\": future_times[:len(predictions)].dayofweek,\n",
    "})\n",
    "\n",
    "# Add day part labels\n",
    "output_df['day_part'] = output_df['hour_of_day'].apply(\n",
    "    lambda h: 'Night' if h < 6 or h >= 22 else 'Morning' if h < 12 else 'Afternoon' if h < 18 else 'Evening'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ONTARIO DEMAND FORECAST: NEXT 24 HOURS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Forecast Date: {future_times[0].strftime('%A, %B %d, %Y')}\")\n",
    "print(f\"Last Known: {last_demand:.1f} MW at {last_time.strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nHour-by-Hour Predictions:\")\n",
    "print(output_df[['time', 'predicted_ontario_demand', 'hour_of_day', 'day_part']].to_string(\n",
    "    index=False, \n",
    "    float_format='%.1f',\n",
    "    formatters={'time': lambda x: x.strftime('%Y-%m-%d %H:%M')}\n",
    "))\n",
    "\n",
    "# ==============================\n",
    "# 11) Statistical analysis\n",
    "# ==============================\n",
    "daytime_hours = output_df[output_df['hour_of_day'].isin(range(6, 20))]\n",
    "night_hours = output_df[~output_df['hour_of_day'].isin(range(6, 20))]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Overall Statistics:\")\n",
    "print(f\"  Mean:   {predictions.mean():.1f} MW\")\n",
    "print(f\"  Min:    {predictions.min():.1f} MW (Hour {predictions.argmin()+1})\")\n",
    "print(f\"  Max:    {predictions.max():.1f} MW (Hour {predictions.argmax()+1})\")\n",
    "print(f\"  Std:    {predictions.std():.1f} MW\")\n",
    "\n",
    "print(f\"\\nDaytime (6am-8pm):\")\n",
    "print(f\"  Average: {daytime_hours['predicted_ontario_demand'].mean():.1f} MW\")\n",
    "print(f\"  Range:   {daytime_hours['predicted_ontario_demand'].min():.1f} - {daytime_hours['predicted_ontario_demand'].max():.1f} MW\")\n",
    "\n",
    "print(f\"\\nNighttime (8pm-6am):\")\n",
    "print(f\"  Average: {night_hours['predicted_ontario_demand'].mean():.1f} MW\") \n",
    "print(f\"  Range:   {night_hours['predicted_ontario_demand'].min():.1f} - {night_hours['predicted_ontario_demand'].max():.1f} MW\")\n",
    "\n",
    "print(f\"\\nPeak Hours:\")\n",
    "peak_3 = output_df.nlargest(3, 'predicted_ontario_demand')[['time', 'predicted_ontario_demand', 'hour_of_day']]\n",
    "print(peak_3.to_string(index=False, float_format='%.1f'))\n",
    "\n",
    "print(f\"\\nLowest Hours:\")\n",
    "low_3 = output_df.nsmallest(3, 'predicted_ontario_demand')[['time', 'predicted_ontario_demand', 'hour_of_day']]\n",
    "print(low_3.to_string(index=False, float_format='%.1f'))\n",
    "\n",
    "# ==============================\n",
    "# 12) Quality validation\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"QUALITY CHECKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for negative values\n",
    "has_negative = (predictions < 0).any()\n",
    "print(f\"Negative values: {'✗ FOUND' if has_negative else '✓ None'}\")\n",
    "if has_negative:\n",
    "    neg_hours = np.where(predictions < 0)[0] + 1\n",
    "    print(f\"  Negative at hours: {neg_hours.tolist()}\")\n",
    "\n",
    "# Check for unrealistic values\n",
    "has_unrealistic = ((predictions < 5000) | (predictions > 30000)).any()\n",
    "print(f\"Unrealistic values (< 5000 or > 30000 MW): {'✗ FOUND' if has_unrealistic else '✓ None'}\")\n",
    "\n",
    "# Check daytime/nighttime patterns\n",
    "daytime_ok = 15000 <= daytime_hours['predicted_ontario_demand'].mean() <= 28000\n",
    "nighttime_ok = 8000 <= night_hours['predicted_ontario_demand'].mean() <= 18000\n",
    "\n",
    "print(f\"Daytime pattern (expect 15,000-28,000 MW): {'✓ Pass' if daytime_ok else '✗ Fail'}\")\n",
    "print(f\"Nighttime pattern (expect 8,000-18,000 MW): {'✓ Pass' if nighttime_ok else '✗ Fail'}\")\n",
    "\n",
    "# Overall assessment\n",
    "all_checks = not has_negative and not has_unrealistic and daytime_ok and nighttime_ok\n",
    "print(f\"\\n{'✓ ALL CHECKS PASSED' if all_checks else '✗ SOME CHECKS FAILED'}\")\n",
    "\n",
    "# ==============================\n",
    "# 13) Save outputs\n",
    "# ==============================\n",
    "output_df.to_csv(\"/kaggle/working/next_day_ontario_forecast.csv\", index=False)\n",
    "print(f\"\\n✓ Predictions saved to /kaggle/working/next_day_ontario_forecast.csv\")\n",
    "\n",
    "# ==============================\n",
    "# 14) Visualization\n",
    "# ==============================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "recent_history = df.tail(168)[[\"time\", \"Ontario Demand\"]]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))\n",
    "\n",
    "# Top plot: Last 7 days + forecast\n",
    "ax1.plot(recent_history[\"time\"], recent_history[\"Ontario Demand\"], \n",
    "         label=\"Historical Demand (Last 7 Days)\", color='green', linewidth=2, alpha=0.8)\n",
    "ax1.plot(output_df[\"time\"], output_df[\"predicted_ontario_demand\"], \n",
    "         marker='o', label=f\"24h Forecast ({future_times[0].strftime('%b %d')})\", \n",
    "         color='blue', linewidth=2.5, markersize=5)\n",
    "ax1.axvline(x=last_time, color='red', linestyle='--', alpha=0.8, linewidth=2,\n",
    "            label='Forecast Start')\n",
    "ax1.set_xlabel(\"Time\", fontsize=12)\n",
    "ax1.set_ylabel(\"Ontario Demand (MW)\", fontsize=12)\n",
    "ax1.set_title(\"Ontario Energy Demand: Historical + Next Day Forecast (TFT Model)\", fontsize=14, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Bottom plot: Forecast only with hour labels\n",
    "ax2.plot(output_df[\"hour_of_day\"], output_df[\"predicted_ontario_demand\"], \n",
    "         marker='o', color='blue', linewidth=2.5, markersize=6)\n",
    "ax2.fill_between(output_df[\"hour_of_day\"], output_df[\"predicted_ontario_demand\"], \n",
    "                  alpha=0.3, color='blue')\n",
    "ax2.set_xlabel(\"Hour of Day\", fontsize=12)\n",
    "ax2.set_ylabel(\"Predicted Demand (MW)\", fontsize=12)\n",
    "ax2.set_title(f\"24-Hour Forecast by Hour ({future_times[0].strftime('%A, %B %d, %Y')})\", \n",
    "              fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(0, 24, 2))\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add shading for day/night\n",
    "ax2.axvspan(0, 6, alpha=0.1, color='gray', label='Night')\n",
    "ax2.axvspan(22, 24, alpha=0.1, color='gray')\n",
    "ax2.axvspan(6, 20, alpha=0.1, color='yellow', label='Daytime')\n",
    "ax2.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/kaggle/working/next_day_demand_forecast.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Visualization saved to /kaggle/working/next_day_demand_forecast.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FORECAST COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Forecasted {len(predictions)} hours starting {future_times[0].strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(f\"Output files saved to /kaggle/working/\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
